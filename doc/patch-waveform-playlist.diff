diff --git a/waveform-playlist.umd.js b/waveform-playlist.umd.js
index 8fe0bb6..1460a01 100644
--- a/waveform-playlist.umd.js
+++ b/waveform-playlist.umd.js
@@ -7168,6 +7168,8 @@ const MAX_CANVAS_WIDTH = 1000;
     this.customClass = undefined;
     this.waveOutlineColor = undefined;
     this.gain = 1;
+    this.muted = false
+    this.soloed = false
     this.fades = {};
     this.peakData = {
       type: "WebAudio",
@@ -7890,6 +7892,8 @@ const MAX_CANVAS_WIDTH = 1000;
       start: this.startTime,
       end: this.endTime,
       name: this.name,
+      muted: this.muted,
+      soloed: this.soloed,
       customClass: this.customClass,
       cuein: this.cueIn,
       cueout: this.cueOut,
@@ -8863,6 +8867,31 @@ class AnnotationList {
     this.exportWorker = new (inline_worker_default())(exportWavWorker);
   }
 
+  trimAudioBuffer (audioBuffer, trimDurationInSeconds) {    
+    const sampleRate = audioBuffer.sampleRate;   
+    const startSample = Math.floor(trimDurationInSeconds * sampleRate);
+    if (startSample >= audioBuffer.length) {
+      // If the trim duration is longer than the audio, return an empty buffer.
+      return this.ac.createBuffer(1, 1, sampleRate);
+    }
+
+    const trimmedBuffer = this.ac.createBuffer(
+      audioBuffer.numberOfChannels,
+      audioBuffer.length - startSample,
+      sampleRate
+    );
+
+    // Copy data from the original buffer to the trimmed buffer, excluding the trimmed part.
+    for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
+      const sourceData = audioBuffer.getChannelData(channel);
+      const destinationData = trimmedBuffer.getChannelData(channel);
+      for (let i = 0; i < trimmedBuffer.length; i++) {
+        destinationData[i] = sourceData[i + startSample];
+      }
+    }
+    return trimmedBuffer;
+  }
+
   // TODO extract into a plugin
   initRecorder(stream) {
     this.mediaRecorder = new MediaRecorder(stream);
@@ -8892,6 +8921,12 @@ class AnnotationList {
         loader
           .load()
           .then((audioBuffer) => {
+            
+            // THIS AFFECTS TO ALL (RECORDED AND PLAYOUT) BUT IT'S CALCULATED EVERY 300 ms
+            if(this.latency > 0){
+              audioBuffer = this.trimAudioBuffer(audioBuffer, this.latency)
+            }
+         
             // ask web worker for peaks.
             this.recorderWorker.postMessage({
               samples: audioBuffer.getChannelData(0),
@@ -8899,6 +8934,8 @@ class AnnotationList {
             });
             this.recordingTrack.setCues(0, audioBuffer.duration);
             this.recordingTrack.setBuffer(audioBuffer);
+            // THIS AFFECTS ONLY TO PLAYOUT IT'S CALCULATED EVERY 300 ms
+            //audioBuffer = this.trimAudioBuffer(audioBuffer, this.latency) // Chrome Mac            
             this.recordingTrack.setPlayout(
               new Playout(this.ac, audioBuffer, this.masterGainNode)
             );
@@ -9036,8 +9073,8 @@ class AnnotationList {
       }
     });
 
-    ee.on("startaudiorendering", (type) => {
-      this.startOfflineRender(type);
+    ee.on("startaudiorendering", (type, trackPos) => {
+      this.startOfflineRender(type, trackPos);
     });
 
     ee.on("statechange", (state) => {
@@ -9051,10 +9088,15 @@ class AnnotationList {
       this.drawRequest();
     });
 
-    ee.on("record", () => {
+    ee.on("record", (latency) => {
+      this.latency = latency
       this.record();
     });
 
+    ee.on("updateview", () => {
+      this.drawRequest();
+    });
+
     ee.on("play", (start, end) => {
       this.play(start, end);
     });
@@ -9323,7 +9365,7 @@ class AnnotationList {
     this.cursor = start;
   }
 
-  async startOfflineRender(type) {
+  async startOfflineRender(type, trackPos) {
     if (this.isRendering) {
       return;
     }
@@ -9346,14 +9388,18 @@ class AnnotationList {
     const currentTime = this.offlineAudioContext.currentTime;
     const mg = this.offlineAudioContext.createGain();
 
-    this.tracks.forEach((track) => {
+    this.tracks.forEach((track, pos) => {
+      let shouldPlay = this.shouldTrackPlay(track)
+      if(trackPos >= 0){
+        shouldPlay = pos === trackPos
+      }
       const playout = new Playout(this.offlineAudioContext, track.buffer, mg);
       playout.setEffects(track.effectsGraph);
       playout.setMasterEffects(this.effectsGraph);
       track.setOfflinePlayout(playout);
 
       track.schedulePlay(currentTime, 0, 0, {
-        shouldPlay: this.shouldTrackPlay(track),
+        shouldPlay: shouldPlay,
         masterGain: 1,
         isOffline: true,
       });
@@ -9363,8 +9409,12 @@ class AnnotationList {
       TODO cleanup of different audio playouts handling.
     */
     await Promise.all(setUpChain);
-    const audioBuffer = await this.offlineAudioContext.startRendering();
+    let audioBuffer = await this.offlineAudioContext.startRendering();
 
+    /*if(trackPos && this.latency) {
+      // TO LISTEN THE FIX MUST REFRESH BROWSER        
+      audioBuffer = this.trimAudioBuffer(audioBuffer, this.latency)
+    } */
     if (type === "buffer") {
       this.ee.emit("audiorenderingfinished", type, audioBuffer);
       this.isRendering = false;
@@ -9378,7 +9428,7 @@ class AnnotationList {
 
       // callback for `exportWAV`
       this.exportWorker.onmessage = (e) => {
-        this.ee.emit("audiorenderingfinished", type, e.data);
+        this.ee.emit("audiorenderingfinished", type, e.data, trackPos);
         this.isRendering = false;
 
         // clear out the buffer for next renderings.
@@ -9437,8 +9487,10 @@ class AnnotationList {
     const index = this.mutedTracks.indexOf(track);
 
     if (index > -1) {
+      track.muted = false
       this.mutedTracks.splice(index, 1);
     } else {
+      track.muted = true
       this.mutedTracks.push(track);
     }
   }
@@ -9447,10 +9499,13 @@ class AnnotationList {
     const index = this.soloedTracks.indexOf(track);
 
     if (index > -1) {
+      track.soloed = false
       this.soloedTracks.splice(index, 1);
     } else if (this.exclSolo) {
+      track.soloed = true
       this.soloedTracks = [track];
     } else {
+      track.soloed = true
       this.soloedTracks.push(track);
     }
   }
@@ -9623,7 +9678,7 @@ class AnnotationList {
     });
 
     // TODO improve this.
-    this.masterGainNode.disconnect();
+    //this.masterGainNode.disconnect();
     this.drawRequest();
     return Promise.all(this.playoutPromises);
   }
@@ -9647,9 +9702,14 @@ class AnnotationList {
     });
   }
 
-  clear() {
+  clear(trackPos) {
     return this.stop().then(() => {
-      this.tracks = [];
+      var newArray = []
+      if(trackPos || trackPos === 0){
+        this.tracks.splice(trackPos, 1)
+        newArray = this.tracks
+      }
+      this.tracks = newArray;
       this.soloedTracks = [];
       this.mutedTracks = [];
       this.playoutPromises = [];
